{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining node of a tree\n",
    "class Node:\n",
    "    def __init__(self,X,y,num_classes):\n",
    "        self.left = None #Left Child\n",
    "        self.right = None #RIght Child\n",
    "        self.X = X #Examples of the current node\n",
    "        self.y = y #Lables of the examples of the current node\n",
    "        self.of_ind = None #optimal feature index\n",
    "        self.ot = None #optimal threshold\n",
    "        self.m = X.shape[0] #number of examples in the current node\n",
    "        self.probs = [0]*num_classes\n",
    "        for i in range(self.m):\n",
    "            self.probs[int(y[i])] = (self.probs[int(y[i])]) + (1/self.m) #probability of each class in the node\n",
    "        self.prediction = self.probs.index(max(self.probs)) # prediction of class on the basis of maximum probability\n",
    "        self.confidence = max(self.probs) * 100 # confidence which is the maximum probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self,max_depth=20):\n",
    "        self.max_depth = max_depth # Max depht of tree is a hyper_parameter to regulate overfitting\n",
    "        self.num_classes = None # Number of classes in the data set\n",
    "        self.root = None\n",
    "        \n",
    "    \n",
    "    def sort_according_to_feature(self,xi,X,y): # Sorting accoring to ith feature\n",
    "        p = X[np.argsort(X[:,xi-1])]\n",
    "        q = y[np.argsort(X[:,xi-1])]\n",
    "        return p,q\n",
    "        \n",
    "    \n",
    "    def find_optimal_threshold_and_feature(self,X,y): #Finding optimal threshold by minimizing Gini impurtiy\n",
    "        m,n = X.shape \n",
    "        self.classes = [0]*self.num_classes\n",
    "        of_ind = None\n",
    "        ot = None\n",
    "        current_gini = 2\n",
    "        for i in range(m):\n",
    "            self.classes[int(y[i])] = self.classes[int(y[i])] +1\n",
    "        \n",
    "        for ind in range(n):\n",
    "            X,y=self.sort_according_to_feature(ind,X,y)\n",
    "            nl=[0]*self.num_classes\n",
    "            nr=self.classes\n",
    "            for i in range(m-1):\n",
    "                nl[int(y[i])] = nl[int(y[i])] + 1\n",
    "                nr[int(y[i])] = nr[int(y[i])] - 1\n",
    "                ct = (X[i][ind] + X[i+1][ind])/2\n",
    "                \n",
    "                gini_left = 1 - sum([(k/m)**2 for k in nl])\n",
    "                gini_right = 1 - sum([(k/m)**2 for k in nr])\n",
    "                gini_node = (i/m)*gini_left + ((m-i)/m)*gini_right\n",
    "                \n",
    "                if gini_node < current_gini:\n",
    "                    \n",
    "                    current_gini = gini_node\n",
    "                    of_ind = ind\n",
    "                    ot = ct\n",
    "        \n",
    "        return [of_ind,ot]\n",
    "    \n",
    "    def split(self, root, depth=0): # Splitting the data recursively on basis of optimal feature and threshold to generate the tree\n",
    "        if root.X.shape[0]<=1 or depth >= self.max_depth:\n",
    "            return None\n",
    "        of_ind, ot = self.find_optimal_threshold_and_feature(root.X,root.y)\n",
    "        r_ind = root.X[:,of_ind] > ot\n",
    "        root.of_ind = of_ind\n",
    "        root.ot = ot\n",
    "        right_X = root.X[r_ind]\n",
    "        right_y = root.y[r_ind]\n",
    "        left_X = root.X[~r_ind]\n",
    "        left_y = root.y[~r_ind]\n",
    "        \n",
    "        rn = Node(right_X,right_y,self.num_classes)\n",
    "        ln = Node(left_X,left_y,self.num_classes)\n",
    "\n",
    "        root.left = self.split(ln,depth+1)\n",
    "        root.right = self.split(rn,depth+1)\n",
    "        return root\n",
    "        \n",
    "    def fit(self,X,y,num_classes): # Fitting the data by training the model\n",
    "        self.root = Node(X,y,num_classes)\n",
    "        self.num_classes = num_classes\n",
    "        self.split(self.root)\n",
    "        \n",
    "    def predict(self,X): #Predicting the given data\n",
    "        m = X.shape[0]\n",
    "        preds = np.array([0]*m)\n",
    "        confidence = np.array([0]*m)\n",
    "        for i in range(m):\n",
    "            c = X[i,:]\n",
    "            temp = self.root\n",
    "            while temp != None:\n",
    "                preds[i] = temp.prediction\n",
    "                confidence[i] = temp.confidence\n",
    "                if c[temp.of_ind] <= temp.ot:\n",
    "                    temp = temp.left\n",
    "                else:\n",
    "                    temp = temp.right\n",
    "                    \n",
    "        return preds,confidence\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "                    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep():\n",
    "    #Loading the data of pulsar stars as numpy array\n",
    "    data = np.genfromtxt(r'C:\\Users\\91888\\Desktop\\Kaggle\\pulsar star\\predicting-a-pulsar-star\\logistic_regression_predict\\pulsar_stars.csv', delimiter = ',', skip_header=1)\n",
    "    \n",
    "    #m is the number of examples(number of rows)\n",
    "    m = data.shape[0]\n",
    "    \n",
    "    #n is 20% of m, as 80% of the data is used for training and 20% for testing(testing data used in predict.py)\n",
    "    n = int(m  * 0.1)\n",
    "    \n",
    "    #Initializing training data\n",
    "    train_data = data[0:m-2*n,:]\n",
    "    cross_val = data[m-2*n:m-n,:]\n",
    "    test_data = data[m-n:m,:]\n",
    "    \n",
    "    \n",
    "    return train_data,cross_val,test_data\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    " train_data,cross_val,test_data = data_prep()\n",
    " a = train_data.shape[1]\n",
    " X = train_data[:,0:a-1]\n",
    " y = train_data[:,a-1:a]\n",
    " # fitting the training data\n",
    " model = DecisionTree()\n",
    " model.fit(X,y,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test---\n",
      "0.6067415730337079\n",
      "cross---\n",
      "0.5977011494252874\n"
     ]
    }
   ],
   "source": [
    " # Testing\n",
    " X_test = test_data[:,0:a-1]\n",
    " y_test = np.reshape(test_data[:,a-1:a],(test_data.shape[0],))\n",
    " preds,confidence = model.predict(X_test)\n",
    " X_cross = cross_val[:,0:a-1]\n",
    " y_cross = np.reshape(cross_val[:,a-1:a],(cross_val.shape[0],))\n",
    " preds_c,confidence_c = model.predict(X_cross)\n",
    " tp = sum(y_test == 1)\n",
    " fp = sum(np.logical_and(y_test == 0,preds == 1))\n",
    " fn = sum(np.logical_and(y_test == 1,preds == 0))\n",
    " tpc = sum(y_cross == 1)\n",
    " fpc = sum(np.logical_and(y_cross == 0,preds_c == 1))\n",
    " fnc = sum(np.logical_and(y_cross == 1,preds_c == 0))\n",
    "  \n",
    "# calculating precision, recall and f1 score on testing and cross_validation data set\n",
    "   \n",
    " p = tp/(tp+fp)\n",
    " r = tp/(tp+fn)\n",
    " pc = tpc/(tpc+fpc)\n",
    " rc = tpc/(tpc+fnc)\n",
    "print(\"test---\")\n",
    "print(2*(p*r)/(p+r))\n",
    "print(\"cross---\")\n",
    "print(2*(pc*rc)/(pc+rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
